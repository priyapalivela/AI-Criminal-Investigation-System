import torch
import torch.nn as nn
import torch.nn.functional as F

class TextEncoder(nn.Module):
    def __init__(self, vocab_size=30522, embed_dim=128):
        super(TextEncoder, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.lstm = nn.LSTM(embed_dim, 128, batch_first=True, bidirectional=True)
        self.dropout = nn.Dropout(0.3)
        self.out_dim = 128 * 2  # Bidirectional LSTM
        
    def forward(self, x):
        # x shape: [batch_size, sequence_length]
        embedded = self.embedding(x.long())
        self.word_embeddings = embedded  # Store for visualization
        x = self.dropout(embedded)
        
        # Pass through LSTM
        output, (h_n, _) = self.lstm(x)
        self.lstm_outputs = output  # Store for visualization
        
        # Concatenate the final forward and backward hidden states
        forward_hidden = h_n[-2, :, :]
        backward_hidden = h_n[-1, :, :]
        combined_hidden = torch.cat((forward_hidden, backward_hidden), dim=1)
        
        return combined_hidden

class AttentionLayer(nn.Module):
    def __init__(self, hidden_dim):
        super(AttentionLayer, self).__init__()
        self.attention = nn.Linear(hidden_dim, 1)
        
    def forward(self, x):
        # x shape: [batch_size, seq_len, hidden_dim]
        attention_weights = F.softmax(self.attention(x), dim=1)
        self.weights = attention_weights  # Store for visualization
        
        # Apply attention weights
        context_vector = torch.sum(attention_weights * x, dim=1)
        return context_vector, attention_weights

class MultimodalFusionModel(nn.Module):
    def __init__(self, audio_dim=40, text_vocab_size=30522, hidden_dim=128, fusion_dim=256, num_classes=3):
        super(MultimodalFusionModel, self).__init__()
        
        # Audio encoder
        self.audio_encoder = AudioEncoder(audio_dim, hidden_dim)
        
        # Text encoder
        self.text_encoder = TextEncoder(text_vocab_size, hidden_dim)
        
        # Attention layer (for explainability)
        self.audio_attention = AttentionLayer(self.audio_encoder.out_dim)
        self.text_attention = AttentionLayer(self.text_encoder.out_dim)
        
        # Fusion layers
        combined_dim = self.audio_encoder.out_dim + self.text_encoder.out_dim
        self.fusion_layer = nn.Sequential(
            nn.Linear(combined_dim, fusion_dim),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(fusion_dim, fusion_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.3)
        )
        
        # Output layers
        self.severity_classifier = nn.Linear(fusion_dim // 2, num_classes)
        
        # Store intermediate representations for explainability
        self.audio_features = None
        self.text_features = None
        self.fused_features = None
        self.modality_importance = None

    def forward(self, audio_input, text_input):
        # Process audio input
        audio_features = self.audio_encoder(audio_input)
        self.audio_features = audio_features.detach()
        
        # Process text input
        text_features = self.text_encoder(text_input)
        self.text_features = text_features.detach()
        
        # Concatenate features
        combined_features = torch.cat((audio_features, text_features), dim=1)
        
        # Calculate modality importance (simple method based on feature magnitudes)
        audio_magnitude = torch.norm(audio_features, dim=1)
        text_magnitude = torch.norm(text_features, dim=1)
        total_magnitude = audio_magnitude + text_magnitude
        self.modality_importance = {
            'audio': (audio_magnitude / total_magnitude).detach(),
            'text': (text_magnitude / total_magnitude).detach()
        }
        
        # Fuse features
        fused_features = self.fusion_layer(combined_features)
        self.fused_features = fused_features.detach()
        
        # Predict severity
        severity_logits = self.severity_classifier(fused_features)
        
        return severity_logits
    
